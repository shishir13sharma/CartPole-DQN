{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import gym\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer, PrioritizedReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(4, 16);\n",
    "        self.l2 = nn.Linear(16, 64);        \n",
    "        self.l3 = nn.Linear(64, 256);\n",
    "        self.l4 = nn.Linear(256, 2);\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))                \n",
    "        x = F.relu(self.l4(x))                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN_learn():\n",
    "    def __init__(self, model, learning_rate, epsilon_sched, gamma, batch_size, act_space):\n",
    "        self.dqn = model\n",
    "        self.target_dqn = deepcopy(model)        \n",
    "        self.optim = optim.Adam(lr= learning_rate, params= self.dqn.parameters())\n",
    "        self.epsilon = epsilon_sched\n",
    "        self.batch_size = batch_size\n",
    "        self.act_space = act_space\n",
    "        \n",
    "        self.replay_buffer = ReplayBuffer(50000)\n",
    "        self.update_freq = 100\n",
    "        self.train_freq = 1\n",
    "        self.t = 1\n",
    "        self.obs_t = np.array([])\n",
    "        \n",
    "    def train(self):        \n",
    "        \n",
    "        buffer_sample = self.replay_buffer.sample(self.batch_size)\n",
    "        obs = torch.from_numpy(buffer_sample[0]).float()\n",
    "        act = torch.from_numpy(buffer_sample[1]).long()\n",
    "        obs1 = torch.from_numpy(buffer_sample[2]).float()\n",
    "        rew = torch.from_numpy(buffer_sample[3]).float()\n",
    "        dones = torch.from_numpy(buffer_sample[4].astype(int)).float()                 \n",
    "                      \n",
    "        val = self.dqn(obs)\n",
    "        val = val.gather(1, act.view(-1, 1)).squeeze() # Q-values of chosen actions\n",
    "        \n",
    "        _, max_act = self.target_dqn(obs1).detach().max(1)\n",
    "        val1 = self.dqn(obs1).detach()\n",
    "        val1 = val1.gather(1, max_act.view(-1, 1)).squeeze()\n",
    "        \n",
    "        targets = rew + gamma*torch.mul(val1, (1 - dones))\n",
    "        \n",
    "        self.optim.zero_grad()\n",
    "        loss = nn.MSELoss()(val, targets)                \n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "                \n",
    "    def step(self, obs_t1, rew_t, done_t):\n",
    "        \n",
    "        self.replay_buffer.add(self.obs_t, self.act_t, obs_t1, rew_t, done_t)\n",
    "        self.obs_t = obs_t1\n",
    "        self.t = self.t + 1        \n",
    "        \n",
    "        if self.t > self.batch_size and self.t%self.train_freq == 0:\n",
    "            self.train()\n",
    "            \n",
    "        if self.t > self.update_freq and self.t%self.update_freq == 0:\n",
    "            self.update_target()\n",
    "        \n",
    "        self.act_t = self.act(obs_t1)\n",
    "        return self.act_t\n",
    "        \n",
    "    def act(self, obs):\n",
    "        random_prob = np.random.binomial(1, self.epsilon.value(t))\n",
    "        \n",
    "        if random_prob == 1 or not obs.tolist() :\n",
    "            \n",
    "            # Act randomly with epsilon probability\n",
    "            curr_act = self.act_space.sample()\n",
    "            \n",
    "            if self.t%100 == 0:\n",
    "                print(\"Exploring with prob \" + str(self.epsilon.value(t)))\n",
    "                                \n",
    "        else:                           \n",
    "            curr_act = np.argmax(self.dqn(torch.from_numpy(obs).float().unsqueeze(0)).detach().numpy())                        \n",
    "            \n",
    "        return curr_act\n",
    "    \n",
    "    def reset(self, obs):\n",
    "        \n",
    "        self.obs_t = obs\n",
    "        self.act_t = self.act(obs)        \n",
    "        return self.act(obs)\n",
    "        \n",
    "    def update_target(self):\n",
    "        self.target_dqn.load_state_dict(self.dqn.state_dict())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps = 0, Episode 0 with reward = 0\n",
      "Steps = 11, Episode 1 with reward = 10.0\n",
      "Steps = 40, Episode 2 with reward = 28.0\n",
      "Steps = 56, Episode 3 with reward = 15.0\n",
      "Steps = 86, Episode 4 with reward = 29.0\n",
      "Exploring with prob 0.9968966666666667\n",
      "Steps = 108, Episode 5 with reward = 21.0\n",
      "Steps = 125, Episode 6 with reward = 16.0\n",
      "Steps = 138, Episode 7 with reward = 12.0\n",
      "Steps = 153, Episode 8 with reward = 14.0\n",
      "Steps = 169, Episode 9 with reward = 15.0\n",
      "Exploring with prob 0.99373\n",
      "Steps = 208, Episode 10 with reward = 38.0\n",
      "Steps = 262, Episode 11 with reward = 53.0\n",
      "Steps = 272, Episode 12 with reward = 9.0\n",
      "Steps = 282, Episode 13 with reward = 9.0\n",
      "Steps = 296, Episode 14 with reward = 13.0\n",
      "Exploring with prob 0.9905633333333334\n",
      "Steps = 324, Episode 15 with reward = 27.0\n",
      "Steps = 369, Episode 16 with reward = 44.0\n",
      "Steps = 383, Episode 17 with reward = 13.0\n",
      "Steps = 396, Episode 18 with reward = 12.0\n",
      "Exploring with prob 0.9873966666666667\n",
      "Steps = 425, Episode 19 with reward = 28.0\n",
      "Steps = 446, Episode 20 with reward = 20.0\n",
      "Steps = 460, Episode 21 with reward = 13.0\n",
      "Steps = 482, Episode 22 with reward = 21.0\n",
      "Exploring with prob 0.98423\n",
      "Steps = 502, Episode 23 with reward = 19.0\n",
      "Steps = 512, Episode 24 with reward = 9.0\n",
      "Steps = 532, Episode 25 with reward = 19.0\n",
      "Steps = 552, Episode 26 with reward = 19.0\n",
      "Steps = 567, Episode 27 with reward = 14.0\n",
      "Steps = 584, Episode 28 with reward = 16.0\n",
      "Exploring with prob 0.9810633333333333\n",
      "Steps = 616, Episode 29 with reward = 31.0\n",
      "Steps = 653, Episode 30 with reward = 36.0\n",
      "Steps = 684, Episode 31 with reward = 30.0\n",
      "Exploring with prob 0.9778966666666666\n",
      "Steps = 710, Episode 32 with reward = 25.0\n",
      "Steps = 766, Episode 33 with reward = 55.0\n",
      "Steps = 784, Episode 34 with reward = 17.0\n",
      "Exploring with prob 0.97473\n",
      "Steps = 802, Episode 35 with reward = 17.0\n",
      "Steps = 822, Episode 36 with reward = 19.0\n",
      "Steps = 835, Episode 37 with reward = 12.0\n",
      "Steps = 847, Episode 38 with reward = 11.0\n",
      "Steps = 864, Episode 39 with reward = 16.0\n",
      "Steps = 874, Episode 40 with reward = 9.0\n",
      "Exploring with prob 0.9715633333333333\n",
      "Steps = 918, Episode 41 with reward = 43.0\n",
      "Steps = 940, Episode 42 with reward = 21.0\n",
      "Steps = 952, Episode 43 with reward = 11.0\n",
      "Steps = 968, Episode 44 with reward = 15.0\n",
      "Steps = 990, Episode 45 with reward = 21.0\n",
      "Exploring with prob 0.9683966666666667\n",
      "Steps = 1009, Episode 46 with reward = 18.0\n",
      "Steps = 1027, Episode 47 with reward = 17.0\n",
      "Steps = 1040, Episode 48 with reward = 12.0\n",
      "Steps = 1085, Episode 49 with reward = 44.0\n",
      "Exploring with prob 0.96523\n",
      "Steps = 1110, Episode 50 with reward = 24.0\n",
      "Steps = 1128, Episode 51 with reward = 17.0\n",
      "Steps = 1143, Episode 52 with reward = 14.0\n",
      "Steps = 1176, Episode 53 with reward = 32.0\n",
      "Steps = 1194, Episode 54 with reward = 17.0\n",
      "Exploring with prob 0.9620633333333334\n",
      "Steps = 1243, Episode 55 with reward = 48.0\n",
      "Steps = 1255, Episode 56 with reward = 11.0\n",
      "Steps = 1274, Episode 57 with reward = 18.0\n",
      "Steps = 1290, Episode 58 with reward = 15.0\n",
      "Exploring with prob 0.9588966666666666\n",
      "Steps = 1303, Episode 59 with reward = 12.0\n",
      "Steps = 1322, Episode 60 with reward = 18.0\n",
      "Steps = 1340, Episode 61 with reward = 17.0\n",
      "Steps = 1355, Episode 62 with reward = 14.0\n",
      "Exploring with prob 0.95573\n",
      "Steps = 1406, Episode 63 with reward = 50.0\n",
      "Steps = 1418, Episode 64 with reward = 11.0\n",
      "Steps = 1441, Episode 65 with reward = 22.0\n",
      "Steps = 1454, Episode 66 with reward = 12.0\n",
      "Steps = 1467, Episode 67 with reward = 12.0\n",
      "Steps = 1482, Episode 68 with reward = 14.0\n",
      "Exploring with prob 0.9525633333333333\n",
      "Steps = 1503, Episode 69 with reward = 20.0\n",
      "Steps = 1519, Episode 70 with reward = 15.0\n",
      "Steps = 1547, Episode 71 with reward = 27.0\n",
      "Steps = 1572, Episode 72 with reward = 24.0\n",
      "Exploring with prob 0.9493966666666667\n",
      "Steps = 1652, Episode 73 with reward = 79.0\n",
      "Steps = 1688, Episode 74 with reward = 35.0\n",
      "Exploring with prob 0.94623\n",
      "Steps = 1708, Episode 75 with reward = 19.0\n",
      "Steps = 1719, Episode 76 with reward = 10.0\n",
      "Steps = 1760, Episode 77 with reward = 40.0\n",
      "Steps = 1776, Episode 78 with reward = 15.0\n",
      "Steps = 1789, Episode 79 with reward = 12.0\n",
      "Exploring with prob 0.9430633333333334\n",
      "Steps = 1802, Episode 80 with reward = 12.0\n",
      "Steps = 1859, Episode 81 with reward = 56.0\n",
      "Steps = 1887, Episode 82 with reward = 27.0\n",
      "Exploring with prob 0.9398966666666667\n",
      "Steps = 1907, Episode 83 with reward = 19.0\n",
      "Steps = 1935, Episode 84 with reward = 27.0\n",
      "Steps = 1947, Episode 85 with reward = 11.0\n",
      "Steps = 1958, Episode 86 with reward = 10.0\n",
      "Steps = 1976, Episode 87 with reward = 17.0\n",
      "Steps = 1991, Episode 88 with reward = 14.0\n",
      "Exploring with prob 0.93673\n",
      "Steps = 2020, Episode 89 with reward = 28.0\n",
      "Steps = 2043, Episode 90 with reward = 22.0\n",
      "Steps = 2061, Episode 91 with reward = 17.0\n",
      "Steps = 2082, Episode 92 with reward = 20.0\n",
      "Exploring with prob 0.9335633333333333\n",
      "Steps = 2109, Episode 93 with reward = 26.0\n",
      "Steps = 2122, Episode 94 with reward = 12.0\n",
      "Steps = 2136, Episode 95 with reward = 13.0\n",
      "Steps = 2154, Episode 96 with reward = 17.0\n",
      "Steps = 2165, Episode 97 with reward = 10.0\n",
      "Steps = 2187, Episode 98 with reward = 21.0\n",
      "Exploring with prob 0.9303966666666666\n",
      "Steps = 2217, Episode 99 with reward = 29.0\n",
      "Steps = 2232, Episode 100 with reward = 14.0\n",
      "Steps = 2245, Episode 101 with reward = 12.0\n",
      "Steps = 2256, Episode 102 with reward = 10.0\n",
      "Steps = 2271, Episode 103 with reward = 14.0\n",
      "Steps = 2282, Episode 104 with reward = 10.0\n",
      "Exploring with prob 0.92723\n",
      "Steps = 2305, Episode 105 with reward = 22.0\n",
      "Steps = 2318, Episode 106 with reward = 12.0\n",
      "Steps = 2334, Episode 107 with reward = 15.0\n",
      "Steps = 2348, Episode 108 with reward = 13.0\n",
      "Steps = 2368, Episode 109 with reward = 19.0\n",
      "Steps = 2378, Episode 110 with reward = 9.0\n",
      "Exploring with prob 0.9240633333333333\n",
      "Steps = 2406, Episode 111 with reward = 27.0\n",
      "Steps = 2435, Episode 112 with reward = 28.0\n",
      "Steps = 2449, Episode 113 with reward = 13.0\n",
      "Steps = 2465, Episode 114 with reward = 15.0\n",
      "Steps = 2488, Episode 115 with reward = 22.0\n",
      "Exploring with prob 0.9208966666666667\n",
      "Steps = 2512, Episode 116 with reward = 23.0\n",
      "Steps = 2526, Episode 117 with reward = 13.0\n",
      "Steps = 2572, Episode 118 with reward = 45.0\n",
      "Steps = 2588, Episode 119 with reward = 15.0\n",
      "Exploring with prob 0.9176983333333333\n",
      "Exploring with prob 0.9176983333333333\n",
      "Steps = 2599, Episode 120 with reward = 10.0\n",
      "Steps = 2618, Episode 121 with reward = 18.0\n",
      "Steps = 2639, Episode 122 with reward = 20.0\n",
      "Steps = 2667, Episode 123 with reward = 27.0\n",
      "Steps = 2686, Episode 124 with reward = 18.0\n",
      "Exploring with prob 0.9145633333333334\n",
      "Steps = 2704, Episode 125 with reward = 17.0\n",
      "Steps = 2734, Episode 126 with reward = 29.0\n",
      "Steps = 2756, Episode 127 with reward = 21.0\n",
      "Steps = 2771, Episode 128 with reward = 14.0\n",
      "Exploring with prob 0.9113966666666666\n",
      "Exploring with prob 0.911365\n",
      "Exploring with prob 0.911365\n",
      "Steps = 2799, Episode 129 with reward = 27.0\n",
      "Steps = 2817, Episode 130 with reward = 17.0\n",
      "Steps = 2834, Episode 131 with reward = 16.0\n",
      "Steps = 2848, Episode 132 with reward = 13.0\n",
      "Steps = 2863, Episode 133 with reward = 14.0\n",
      "Steps = 2887, Episode 134 with reward = 23.0\n",
      "Exploring with prob 0.90823\n",
      "Steps = 2905, Episode 135 with reward = 17.0\n",
      "Steps = 2921, Episode 136 with reward = 15.0\n",
      "Steps = 2960, Episode 137 with reward = 38.0\n",
      "Steps = 2972, Episode 138 with reward = 11.0\n",
      "Steps = 2992, Episode 139 with reward = 19.0\n",
      "Exploring with prob 0.9050633333333333\n",
      "Steps = 3003, Episode 140 with reward = 10.0\n",
      "Steps = 3020, Episode 141 with reward = 16.0\n",
      "Steps = 3042, Episode 142 with reward = 21.0\n",
      "Steps = 3082, Episode 143 with reward = 39.0\n",
      "Exploring with prob 0.9018966666666667\n",
      "Exploring with prob 0.901865\n",
      "Exploring with prob 0.901865\n",
      "Steps = 3099, Episode 144 with reward = 16.0\n",
      "Steps = 3109, Episode 145 with reward = 9.0\n",
      "Steps = 3127, Episode 146 with reward = 17.0\n",
      "Steps = 3145, Episode 147 with reward = 17.0\n",
      "Steps = 3176, Episode 148 with reward = 30.0\n",
      "Steps = 3191, Episode 149 with reward = 14.0\n",
      "Exploring with prob 0.89873\n",
      "Steps = 3208, Episode 150 with reward = 16.0\n",
      "Steps = 3238, Episode 151 with reward = 29.0\n",
      "Steps = 3250, Episode 152 with reward = 11.0\n",
      "Steps = 3263, Episode 153 with reward = 12.0\n",
      "Steps = 3286, Episode 154 with reward = 22.0\n",
      "Exploring with prob 0.8955633333333334\n",
      "Steps = 3300, Episode 155 with reward = 13.0\n",
      "Steps = 3323, Episode 156 with reward = 22.0\n",
      "Steps = 3334, Episode 157 with reward = 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps = 3347, Episode 158 with reward = 12.0\n",
      "Exploring with prob 0.8923966666666667\n",
      "Steps = 3424, Episode 159 with reward = 76.0\n",
      "Steps = 3437, Episode 160 with reward = 12.0\n",
      "Steps = 3447, Episode 161 with reward = 9.0\n",
      "Steps = 3462, Episode 162 with reward = 14.0\n",
      "Steps = 3479, Episode 163 with reward = 16.0\n",
      "Steps = 3488, Episode 164 with reward = 8.0\n",
      "Exploring with prob 0.88923\n",
      "Exploring with prob 0.8891983333333333\n",
      "Exploring with prob 0.8891983333333333\n",
      "Steps = 3499, Episode 165 with reward = 10.0\n",
      "Steps = 3557, Episode 166 with reward = 57.0\n",
      "Steps = 3577, Episode 167 with reward = 19.0\n",
      "Exploring with prob 0.8860633333333333\n",
      "Steps = 3600, Episode 168 with reward = 22.0\n",
      "Steps = 3626, Episode 169 with reward = 25.0\n",
      "Steps = 3648, Episode 170 with reward = 21.0\n",
      "Steps = 3657, Episode 171 with reward = 8.0\n",
      "Steps = 3671, Episode 172 with reward = 13.0\n",
      "Steps = 3690, Episode 173 with reward = 18.0\n",
      "Exploring with prob 0.8828966666666667\n",
      "Steps = 3729, Episode 174 with reward = 38.0\n",
      "Steps = 3745, Episode 175 with reward = 15.0\n",
      "Steps = 3760, Episode 176 with reward = 14.0\n",
      "Exploring with prob 0.87973\n",
      "Steps = 3812, Episode 177 with reward = 51.0\n",
      "Steps = 3838, Episode 178 with reward = 25.0\n",
      "Steps = 3852, Episode 179 with reward = 13.0\n",
      "Exploring with prob 0.8765633333333334\n",
      "Steps = 3909, Episode 180 with reward = 56.0\n",
      "Steps = 3925, Episode 181 with reward = 15.0\n",
      "Steps = 3962, Episode 182 with reward = 36.0\n",
      "Steps = 3971, Episode 183 with reward = 8.0\n",
      "Exploring with prob 0.8733966666666666\n",
      "Steps = 4010, Episode 184 with reward = 38.0\n",
      "Steps = 4040, Episode 185 with reward = 29.0\n",
      "Steps = 4064, Episode 186 with reward = 23.0\n",
      "Steps = 4077, Episode 187 with reward = 12.0\n",
      "Steps = 4097, Episode 188 with reward = 19.0\n",
      "Exploring with prob 0.8702300000000001\n",
      "Steps = 4108, Episode 189 with reward = 10.0\n",
      "Steps = 4127, Episode 190 with reward = 18.0\n",
      "Steps = 4145, Episode 191 with reward = 17.0\n",
      "Steps = 4159, Episode 192 with reward = 13.0\n",
      "Steps = 4174, Episode 193 with reward = 14.0\n",
      "Steps = 4190, Episode 194 with reward = 15.0\n",
      "Exploring with prob 0.8670633333333333\n",
      "Steps = 4208, Episode 195 with reward = 17.0\n",
      "Steps = 4223, Episode 196 with reward = 14.0\n",
      "Steps = 4242, Episode 197 with reward = 18.0\n",
      "Steps = 4257, Episode 198 with reward = 14.0\n",
      "Steps = 4267, Episode 199 with reward = 9.0\n",
      "Steps = 4290, Episode 200 with reward = 22.0\n",
      "Exploring with prob 0.8638966666666666\n",
      "Steps = 4319, Episode 201 with reward = 28.0\n",
      "Steps = 4331, Episode 202 with reward = 11.0\n",
      "Steps = 4346, Episode 203 with reward = 14.0\n",
      "Steps = 4358, Episode 204 with reward = 11.0\n",
      "Steps = 4370, Episode 205 with reward = 11.0\n",
      "Steps = 4395, Episode 206 with reward = 24.0\n",
      "Steps = 4409, Episode 207 with reward = 13.0\n",
      "Steps = 4438, Episode 208 with reward = 28.0\n",
      "Steps = 4460, Episode 209 with reward = 21.0\n",
      "Steps = 4471, Episode 210 with reward = 10.0\n",
      "Steps = 4483, Episode 211 with reward = 11.0\n",
      "Exploring with prob 0.8575633333333333\n",
      "Steps = 4504, Episode 212 with reward = 20.0\n",
      "Steps = 4524, Episode 213 with reward = 19.0\n",
      "Steps = 4538, Episode 214 with reward = 13.0\n",
      "Steps = 4557, Episode 215 with reward = 18.0\n",
      "Steps = 4569, Episode 216 with reward = 11.0\n",
      "Steps = 4586, Episode 217 with reward = 16.0\n",
      "Exploring with prob 0.8543966666666667\n",
      "Steps = 4623, Episode 218 with reward = 36.0\n",
      "Steps = 4656, Episode 219 with reward = 32.0\n",
      "Steps = 4678, Episode 220 with reward = 21.0\n",
      "Steps = 4697, Episode 221 with reward = 18.0\n",
      "Exploring with prob 0.85123\n",
      "Steps = 4711, Episode 222 with reward = 13.0\n",
      "Steps = 4748, Episode 223 with reward = 36.0\n",
      "Steps = 4769, Episode 224 with reward = 20.0\n",
      "Steps = 4783, Episode 225 with reward = 13.0\n",
      "Exploring with prob 0.8480633333333334\n",
      "Steps = 4808, Episode 226 with reward = 24.0\n",
      "Steps = 4834, Episode 227 with reward = 25.0\n",
      "Steps = 4873, Episode 228 with reward = 38.0\n",
      "Steps = 4889, Episode 229 with reward = 15.0\n",
      "Exploring with prob 0.8448966666666666\n",
      "Steps = 4917, Episode 230 with reward = 27.0\n",
      "Steps = 4933, Episode 231 with reward = 15.0\n",
      "Steps = 4956, Episode 232 with reward = 22.0\n",
      "Steps = 4979, Episode 233 with reward = 22.0\n",
      "Steps = 4998, Episode 234 with reward = 18.0\n",
      "Exploring with prob 0.84173\n",
      "Steps = 5029, Episode 235 with reward = 30.0\n",
      "Steps = 5059, Episode 236 with reward = 29.0\n",
      "Steps = 5090, Episode 237 with reward = 30.0\n",
      "Exploring with prob 0.8385633333333333\n",
      "Steps = 5107, Episode 238 with reward = 16.0\n",
      "Steps = 5126, Episode 239 with reward = 18.0\n",
      "Steps = 5144, Episode 240 with reward = 17.0\n",
      "Steps = 5173, Episode 241 with reward = 28.0\n",
      "Exploring with prob 0.8353966666666667\n",
      "Steps = 5226, Episode 242 with reward = 52.0\n",
      "Steps = 5243, Episode 243 with reward = 16.0\n",
      "Steps = 5268, Episode 244 with reward = 24.0\n",
      "Exploring with prob 0.83223\n",
      "Steps = 5330, Episode 245 with reward = 61.0\n",
      "Steps = 5353, Episode 246 with reward = 22.0\n",
      "Steps = 5381, Episode 247 with reward = 27.0\n",
      "Exploring with prob 0.8290633333333334\n",
      "Steps = 5420, Episode 248 with reward = 38.0\n",
      "Steps = 5452, Episode 249 with reward = 31.0\n",
      "Steps = 5481, Episode 250 with reward = 28.0\n",
      "Exploring with prob 0.8258966666666667\n",
      "Exploring with prob 0.8258650000000001\n",
      "Exploring with prob 0.8258650000000001\n",
      "Steps = 5499, Episode 251 with reward = 17.0\n",
      "Steps = 5531, Episode 252 with reward = 31.0\n",
      "Steps = 5557, Episode 253 with reward = 25.0\n",
      "Steps = 5593, Episode 254 with reward = 35.0\n",
      "Exploring with prob 0.82273\n",
      "Steps = 5619, Episode 255 with reward = 25.0\n",
      "Steps = 5639, Episode 256 with reward = 19.0\n",
      "Steps = 5682, Episode 257 with reward = 42.0\n",
      "Exploring with prob 0.8195633333333333\n",
      "Exploring with prob 0.8195316666666667\n",
      "Exploring with prob 0.8195316666666667\n",
      "Steps = 5699, Episode 258 with reward = 16.0\n",
      "Steps = 5729, Episode 259 with reward = 29.0\n",
      "Steps = 5754, Episode 260 with reward = 24.0\n",
      "Steps = 5778, Episode 261 with reward = 23.0\n",
      "Steps = 5789, Episode 262 with reward = 10.0\n",
      "Steps = 5827, Episode 263 with reward = 37.0\n",
      "Steps = 5844, Episode 264 with reward = 16.0\n",
      "Steps = 5874, Episode 265 with reward = 29.0\n",
      "Exploring with prob 0.81323\n",
      "Steps = 5904, Episode 266 with reward = 29.0\n",
      "Steps = 5918, Episode 267 with reward = 13.0\n",
      "Steps = 5974, Episode 268 with reward = 55.0\n",
      "Exploring with prob 0.8100633333333334\n",
      "Steps = 6024, Episode 269 with reward = 49.0\n",
      "Steps = 6054, Episode 270 with reward = 29.0\n",
      "Steps = 6078, Episode 271 with reward = 23.0\n",
      "Exploring with prob 0.8068966666666666\n",
      "Steps = 6115, Episode 272 with reward = 36.0\n",
      "Steps = 6145, Episode 273 with reward = 29.0\n",
      "Steps = 6238, Episode 274 with reward = 92.0\n",
      "Steps = 6254, Episode 275 with reward = 15.0\n",
      "Exploring with prob 0.8005633333333333\n",
      "Steps = 6306, Episode 276 with reward = 51.0\n",
      "Steps = 6326, Episode 277 with reward = 19.0\n",
      "Steps = 6433, Episode 278 with reward = 106.0\n",
      "Steps = 6454, Episode 279 with reward = 20.0\n",
      "Steps = 6476, Episode 280 with reward = 21.0\n",
      "Exploring with prob 0.79423\n",
      "Steps = 6505, Episode 281 with reward = 28.0\n",
      "Steps = 6518, Episode 282 with reward = 12.0\n",
      "Exploring with prob 0.7910633333333333\n",
      "Exploring with prob 0.7910316666666667\n",
      "Exploring with prob 0.7910316666666667\n",
      "Steps = 6599, Episode 283 with reward = 80.0\n",
      "Steps = 6620, Episode 284 with reward = 20.0\n",
      "Steps = 6645, Episode 285 with reward = 24.0\n",
      "Steps = 6689, Episode 286 with reward = 43.0\n",
      "Steps = 6707, Episode 287 with reward = 17.0\n",
      "Steps = 6754, Episode 288 with reward = 46.0\n",
      "Steps = 6769, Episode 289 with reward = 14.0\n",
      "Exploring with prob 0.78473\n",
      "Steps = 6819, Episode 290 with reward = 49.0\n",
      "Steps = 6840, Episode 291 with reward = 20.0\n",
      "Steps = 6879, Episode 292 with reward = 38.0\n",
      "Exploring with prob 0.7815633333333334\n",
      "Steps = 6927, Episode 293 with reward = 47.0\n",
      "Steps = 6960, Episode 294 with reward = 32.0\n",
      "Steps = 6977, Episode 295 with reward = 16.0\n",
      "Exploring with prob 0.7783966666666666\n",
      "Steps = 7024, Episode 296 with reward = 46.0\n",
      "Steps = 7053, Episode 297 with reward = 28.0\n",
      "Steps = 7069, Episode 298 with reward = 15.0\n",
      "Steps = 7083, Episode 299 with reward = 13.0\n",
      "Exploring with prob 0.77523\n",
      "Steps = 7168, Episode 300 with reward = 84.0\n",
      "Exploring with prob 0.7720633333333333\n",
      "Steps = 7208, Episode 301 with reward = 39.0\n",
      "Steps = 7233, Episode 302 with reward = 24.0\n",
      "Steps = 7256, Episode 303 with reward = 22.0\n",
      "Steps = 7272, Episode 304 with reward = 15.0\n",
      "Exploring with prob 0.7688966666666667\n",
      "Steps = 7319, Episode 305 with reward = 46.0\n",
      "Steps = 7338, Episode 306 with reward = 18.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps = 7349, Episode 307 with reward = 10.0\n",
      "Steps = 7364, Episode 308 with reward = 14.0\n",
      "Steps = 7397, Episode 309 with reward = 32.0\n",
      "Steps = 7424, Episode 310 with reward = 26.0\n",
      "Steps = 7459, Episode 311 with reward = 34.0\n",
      "Steps = 7498, Episode 312 with reward = 38.0\n",
      "Steps = 7561, Episode 313 with reward = 62.0\n",
      "Steps = 7575, Episode 314 with reward = 13.0\n",
      "Steps = 7598, Episode 315 with reward = 22.0\n",
      "Exploring with prob 0.7593966666666667\n",
      "Steps = 7622, Episode 316 with reward = 23.0\n",
      "Steps = 7678, Episode 317 with reward = 55.0\n",
      "Steps = 7691, Episode 318 with reward = 12.0\n",
      "Exploring with prob 0.75623\n",
      "Steps = 7733, Episode 319 with reward = 41.0\n",
      "Steps = 7763, Episode 320 with reward = 29.0\n",
      "Steps = 7775, Episode 321 with reward = 11.0\n",
      "Steps = 7815, Episode 322 with reward = 39.0\n",
      "Steps = 7843, Episode 323 with reward = 27.0\n",
      "Steps = 7872, Episode 324 with reward = 28.0\n",
      "Exploring with prob 0.7498966666666667\n",
      "Steps = 7964, Episode 325 with reward = 91.0\n",
      "Exploring with prob 0.74673\n",
      "Steps = 8002, Episode 326 with reward = 37.0\n",
      "Steps = 8061, Episode 327 with reward = 58.0\n",
      "Steps = 8082, Episode 328 with reward = 20.0\n",
      "Exploring with prob 0.7435633333333334\n",
      "Steps = 8103, Episode 329 with reward = 20.0\n",
      "Steps = 8132, Episode 330 with reward = 28.0\n",
      "Steps = 8173, Episode 331 with reward = 40.0\n",
      "Steps = 8213, Episode 332 with reward = 39.0\n",
      "Steps = 8241, Episode 333 with reward = 27.0\n",
      "Steps = 8260, Episode 334 with reward = 18.0\n",
      "Steps = 8293, Episode 335 with reward = 32.0\n",
      "Exploring with prob 0.73723\n",
      "Steps = 8340, Episode 336 with reward = 46.0\n",
      "Steps = 8390, Episode 337 with reward = 49.0\n",
      "Exploring with prob 0.7340633333333333\n",
      "Steps = 8427, Episode 338 with reward = 36.0\n",
      "Steps = 8445, Episode 339 with reward = 17.0\n",
      "Exploring with prob 0.7308966666666667\n",
      "Steps = 8554, Episode 340 with reward = 108.0\n",
      "Steps = 8591, Episode 341 with reward = 36.0\n",
      "Steps = 8653, Episode 342 with reward = 61.0\n",
      "Steps = 8687, Episode 343 with reward = 33.0\n",
      "Exploring with prob 0.7245633333333333\n",
      "Steps = 8732, Episode 344 with reward = 44.0\n",
      "Steps = 8762, Episode 345 with reward = 29.0\n",
      "Steps = 8785, Episode 346 with reward = 22.0\n",
      "Exploring with prob 0.7213966666666667\n",
      "Steps = 8805, Episode 347 with reward = 19.0\n",
      "Steps = 8829, Episode 348 with reward = 23.0\n",
      "Exploring with prob 0.71823\n",
      "Steps = 8910, Episode 349 with reward = 80.0\n",
      "Steps = 8970, Episode 350 with reward = 59.0\n",
      "Steps = 9057, Episode 351 with reward = 86.0\n",
      "Steps = 9095, Episode 352 with reward = 37.0\n",
      "Exploring with prob 0.7118966666666666\n",
      "Steps = 9104, Episode 353 with reward = 8.0\n",
      "Steps = 9134, Episode 354 with reward = 29.0\n",
      "Steps = 9219, Episode 355 with reward = 84.0\n",
      "Steps = 9292, Episode 356 with reward = 72.0\n",
      "Exploring with prob 0.7055633333333333\n",
      "Steps = 9357, Episode 357 with reward = 64.0\n",
      "Exploring with prob 0.7023966666666667\n",
      "Steps = 9415, Episode 358 with reward = 57.0\n",
      "Steps = 9433, Episode 359 with reward = 17.0\n",
      "Steps = 9481, Episode 360 with reward = 47.0\n",
      "Exploring with prob 0.69923\n",
      "Steps = 9555, Episode 361 with reward = 73.0\n",
      "Steps = 9583, Episode 362 with reward = 27.0\n",
      "Exploring with prob 0.6960633333333333\n",
      "Steps = 9613, Episode 363 with reward = 29.0\n",
      "Steps = 9638, Episode 364 with reward = 24.0\n",
      "Steps = 9686, Episode 365 with reward = 47.0\n",
      "Steps = 9710, Episode 366 with reward = 23.0\n",
      "Steps = 9788, Episode 367 with reward = 77.0\n",
      "Exploring with prob 0.68973\n",
      "Steps = 9877, Episode 368 with reward = 88.0\n",
      "Exploring with prob 0.6865633333333333\n",
      "Steps = 9910, Episode 369 with reward = 32.0\n",
      "Steps = 9932, Episode 370 with reward = 21.0\n",
      "Steps = 9990, Episode 371 with reward = 57.0\n",
      "Exploring with prob 0.6833966666666667\n",
      "Steps = 10038, Episode 372 with reward = 47.0\n",
      "Steps = 10072, Episode 373 with reward = 33.0\n",
      "Steps = 10116, Episode 374 with reward = 43.0\n",
      "Steps = 10127, Episode 375 with reward = 10.0\n",
      "Steps = 10170, Episode 376 with reward = 42.0\n",
      "Exploring with prob 0.6770633333333334\n",
      "Steps = 10243, Episode 377 with reward = 72.0\n",
      "Steps = 10275, Episode 378 with reward = 31.0\n",
      "Steps = 10296, Episode 379 with reward = 20.0\n",
      "Exploring with prob 0.6738966666666667\n",
      "Steps = 10321, Episode 380 with reward = 24.0\n",
      "Steps = 10379, Episode 381 with reward = 57.0\n",
      "Steps = 10396, Episode 382 with reward = 16.0\n",
      "Exploring with prob 0.67073\n",
      "Steps = 10419, Episode 383 with reward = 22.0\n",
      "Steps = 10446, Episode 384 with reward = 26.0\n",
      "Exploring with prob 0.6675633333333333\n",
      "Steps = 10532, Episode 385 with reward = 85.0\n",
      "Steps = 10580, Episode 386 with reward = 47.0\n",
      "Exploring with prob 0.6643966666666667\n",
      "Steps = 10608, Episode 387 with reward = 27.0\n",
      "Steps = 10642, Episode 388 with reward = 33.0\n",
      "Steps = 10695, Episode 389 with reward = 52.0\n",
      "Exploring with prob 0.6580633333333333\n",
      "Steps = 10813, Episode 390 with reward = 117.0\n",
      "Steps = 10828, Episode 391 with reward = 14.0\n",
      "Steps = 10868, Episode 392 with reward = 39.0\n",
      "Steps = 10910, Episode 393 with reward = 41.0\n",
      "Steps = 10976, Episode 394 with reward = 65.0\n",
      "Steps = 10993, Episode 395 with reward = 16.0\n",
      "Steps = 11043, Episode 396 with reward = 49.0\n",
      "Steps = 11071, Episode 397 with reward = 27.0\n",
      "Steps = 11215, Episode 398 with reward = 143.0\n",
      "Steps = 11256, Episode 399 with reward = 40.0\n",
      "Steps = 11328, Episode 400 with reward = 71.0\n",
      "Steps = 11357, Episode 401 with reward = 28.0\n",
      "Exploring with prob 0.6390633333333333\n",
      "Steps = 11426, Episode 402 with reward = 68.0\n",
      "Steps = 11489, Episode 403 with reward = 62.0\n",
      "Steps = 11545, Episode 404 with reward = 55.0\n",
      "Steps = 11598, Episode 405 with reward = 52.0\n",
      "Exploring with prob 0.63273\n",
      "Exploring with prob 0.6295633333333333\n",
      "Steps = 11798, Episode 406 with reward = 199.0\n",
      "Exploring with prob 0.6263966666666667\n",
      "Steps = 11888, Episode 407 with reward = 89.0\n",
      "Exploring with prob 0.62323\n",
      "Steps = 11906, Episode 408 with reward = 17.0\n",
      "Steps = 11966, Episode 409 with reward = 59.0\n",
      "Exploring with prob 0.6200633333333334\n",
      "Steps = 12077, Episode 410 with reward = 110.0\n",
      "Steps = 12106, Episode 411 with reward = 28.0\n",
      "Steps = 12136, Episode 412 with reward = 29.0\n",
      "Steps = 12166, Episode 413 with reward = 29.0\n",
      "Steps = 12190, Episode 414 with reward = 23.0\n",
      "Exploring with prob 0.61373\n",
      "Steps = 12206, Episode 415 with reward = 15.0\n",
      "Steps = 12243, Episode 416 with reward = 36.0\n",
      "Steps = 12320, Episode 417 with reward = 76.0\n",
      "Exploring with prob 0.6073966666666667\n",
      "Steps = 12412, Episode 418 with reward = 91.0\n",
      "Steps = 12491, Episode 419 with reward = 78.0\n",
      "Steps = 12580, Episode 420 with reward = 88.0\n",
      "Exploring with prob 0.6010633333333333\n",
      "Steps = 12606, Episode 421 with reward = 25.0\n",
      "Steps = 12682, Episode 422 with reward = 75.0\n",
      "Steps = 12694, Episode 423 with reward = 11.0\n",
      "Exploring with prob 0.5978966666666667\n",
      "Steps = 12828, Episode 424 with reward = 133.0\n",
      "Exploring with prob 0.5915633333333333\n",
      "Steps = 12900, Episode 425 with reward = 71.0\n",
      "Steps = 12950, Episode 426 with reward = 49.0\n",
      "Steps = 12967, Episode 427 with reward = 16.0\n",
      "Exploring with prob 0.5883966666666667\n",
      "Steps = 13084, Episode 428 with reward = 116.0\n",
      "Exploring with prob 0.58523\n",
      "Steps = 13106, Episode 429 with reward = 21.0\n",
      "Steps = 13193, Episode 430 with reward = 86.0\n",
      "Exploring with prob 0.5820633333333334\n",
      "Steps = 13243, Episode 431 with reward = 49.0\n",
      "Exploring with prob 0.5788966666666667\n",
      "Steps = 13329, Episode 432 with reward = 85.0\n",
      "Steps = 13369, Episode 433 with reward = 39.0\n",
      "Exploring with prob 0.5757300000000001\n",
      "Exploring with prob 0.5725633333333333\n",
      "Steps = 13542, Episode 434 with reward = 172.0\n",
      "Steps = 13615, Episode 435 with reward = 72.0\n",
      "Steps = 13636, Episode 436 with reward = 20.0\n",
      "Steps = 13765, Episode 437 with reward = 128.0\n",
      "Exploring with prob 0.5598966666666667\n",
      "Steps = 13940, Episode 438 with reward = 174.0\n",
      "Exploring with prob 0.55673\n",
      "Steps = 14003, Episode 439 with reward = 62.0\n",
      "Steps = 14062, Episode 440 with reward = 58.0\n",
      "Exploring with prob 0.5535633333333334\n",
      "Steps = 14126, Episode 441 with reward = 63.0\n",
      "Steps = 14186, Episode 442 with reward = 59.0\n",
      "Exploring with prob 0.54723\n",
      "Steps = 14303, Episode 443 with reward = 116.0\n",
      "Steps = 14357, Episode 444 with reward = 53.0\n",
      "Exploring with prob 0.5440633333333333\n",
      "Steps = 14438, Episode 445 with reward = 80.0\n",
      "Exploring with prob 0.5408966666666667\n",
      "Steps = 14567, Episode 446 with reward = 128.0\n",
      "Exploring with prob 0.53773\n",
      "Steps = 14677, Episode 447 with reward = 109.0\n",
      "Exploring with prob 0.5345633333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps = 14752, Episode 448 with reward = 74.0\n",
      "Exploring with prob 0.5313966666666667\n",
      "Steps = 14846, Episode 449 with reward = 93.0\n",
      "Exploring with prob 0.52823\n",
      "Steps = 14958, Episode 450 with reward = 111.0\n",
      "Exploring with prob 0.5250633333333333\n",
      "Steps = 15022, Episode 451 with reward = 63.0\n",
      "Exploring with prob 0.5218966666666667\n",
      "Steps = 15136, Episode 452 with reward = 113.0\n",
      "Steps = 15165, Episode 453 with reward = 28.0\n",
      "Steps = 15255, Episode 454 with reward = 89.0\n",
      "Steps = 15282, Episode 455 with reward = 26.0\n",
      "Exploring with prob 0.5123966666666667\n",
      "Steps = 15445, Episode 456 with reward = 162.0\n",
      "Steps = 15537, Episode 457 with reward = 91.0\n",
      "Exploring with prob 0.5060633333333333\n",
      "Steps = 15676, Episode 458 with reward = 138.0\n",
      "Exploring with prob 0.5028966666666668\n",
      "Steps = 15840, Episode 459 with reward = 163.0\n",
      "Exploring with prob 0.49656333333333336\n",
      "Steps = 15905, Episode 460 with reward = 64.0\n",
      "Exploring with prob 0.4933966666666667\n",
      "Steps = 16008, Episode 461 with reward = 102.0\n",
      "Steps = 16052, Episode 462 with reward = 43.0\n",
      "Steps = 16143, Episode 463 with reward = 90.0\n",
      "Exploring with prob 0.4870633333333333\n",
      "Steps = 16201, Episode 464 with reward = 57.0\n",
      "Steps = 16336, Episode 465 with reward = 134.0\n",
      "Steps = 16387, Episode 466 with reward = 50.0\n",
      "Steps = 16419, Episode 467 with reward = 31.0\n",
      "Steps = 16467, Episode 468 with reward = 47.0\n",
      "Steps = 16552, Episode 469 with reward = 84.0\n",
      "Steps = 16657, Episode 470 with reward = 104.0\n",
      "Steps = 16692, Episode 471 with reward = 34.0\n",
      "Steps = 16887, Episode 472 with reward = 194.0\n",
      "Exploring with prob 0.4648966666666666\n",
      "Steps = 17087, Episode 473 with reward = 199.0\n",
      "Exploring with prob 0.45856333333333343\n",
      "Steps = 17287, Episode 474 with reward = 199.0\n",
      "Exploring with prob 0.45223\n",
      "Steps = 17449, Episode 475 with reward = 161.0\n",
      "Exploring with prob 0.4458966666666666\n",
      "Steps = 17540, Episode 476 with reward = 90.0\n",
      "Steps = 17630, Episode 477 with reward = 89.0\n",
      "Steps = 17661, Episode 478 with reward = 30.0\n",
      "Exploring with prob 0.43639666666666665\n",
      "Steps = 17824, Episode 479 with reward = 162.0\n",
      "Steps = 17868, Episode 480 with reward = 43.0\n",
      "Exploring with prob 0.43323\n",
      "Steps = 17962, Episode 481 with reward = 93.0\n",
      "Steps = 17987, Episode 482 with reward = 24.0\n",
      "Exploring with prob 0.43006333333333335\n",
      "Steps = 18139, Episode 483 with reward = 151.0\n",
      "Steps = 18195, Episode 484 with reward = 55.0\n",
      "Exploring with prob 0.42373000000000005\n",
      "Exploring with prob 0.4205633333333334\n",
      "Steps = 18390, Episode 485 with reward = 194.0\n",
      "Steps = 18590, Episode 486 with reward = 199.0\n",
      "Exploring with prob 0.41106333333333334\n",
      "Steps = 18725, Episode 487 with reward = 134.0\n",
      "Exploring with prob 0.40473000000000003\n",
      "Steps = 18897, Episode 488 with reward = 171.0\n",
      "Exploring with prob 0.4015633333333334\n",
      "Steps = 19029, Episode 489 with reward = 131.0\n",
      "Exploring with prob 0.39522999999999997\n",
      "Steps = 19180, Episode 490 with reward = 150.0\n",
      "Exploring with prob 0.3920633333333333\n",
      "Exploring with prob 0.38889666666666667\n",
      "Steps = 19362, Episode 491 with reward = 181.0\n",
      "Steps = 19501, Episode 492 with reward = 138.0\n",
      "Steps = 19690, Episode 493 with reward = 188.0\n",
      "Steps = 19890, Episode 494 with reward = 199.0\n",
      "Exploring with prob 0.36989666666666665\n",
      "Exploring with prob 0.3667300000000001\n",
      "Steps = 20059, Episode 495 with reward = 168.0\n",
      "Steps = 20259, Episode 496 with reward = 199.0\n",
      "Exploring with prob 0.3540633333333334\n",
      "Steps = 20459, Episode 497 with reward = 199.0\n",
      "Exploring with prob 0.35089666666666663\n",
      "Exploring with prob 0.3477300000000001\n",
      "Steps = 20659, Episode 498 with reward = 199.0\n",
      "Exploring with prob 0.34456333333333344\n",
      "Steps = 20801, Episode 499 with reward = 141.0\n",
      "Steps = 21001, Episode 500 with reward = 199.0\n",
      "Steps = 21096, Episode 501 with reward = 94.0\n",
      "Exploring with prob 0.3287300000000001\n",
      "Steps = 21233, Episode 502 with reward = 136.0\n",
      "Exploring with prob 0.32239666666666666\n",
      "Steps = 21402, Episode 503 with reward = 168.0\n",
      "Steps = 21575, Episode 504 with reward = 172.0\n",
      "Steps = 21731, Episode 505 with reward = 155.0\n",
      "Steps = 21847, Episode 506 with reward = 115.0\n",
      "Steps = 22047, Episode 507 with reward = 199.0\n",
      "Exploring with prob 0.30023\n",
      "Steps = 22213, Episode 508 with reward = 165.0\n",
      "Steps = 22382, Episode 509 with reward = 168.0\n",
      "Steps = 22582, Episode 510 with reward = 199.0\n",
      "Steps = 22782, Episode 511 with reward = 199.0\n",
      "Steps = 22954, Episode 512 with reward = 171.0\n",
      "Steps = 23154, Episode 513 with reward = 199.0\n",
      "Steps = 23354, Episode 514 with reward = 199.0\n",
      "Exploring with prob 0.25589666666666666\n",
      "Steps = 23522, Episode 515 with reward = 167.0\n",
      "Exploring with prob 0.2527300000000001\n",
      "Steps = 23722, Episode 516 with reward = 199.0\n",
      "Exploring with prob 0.24323000000000006\n",
      "Steps = 23922, Episode 517 with reward = 199.0\n",
      "Exploring with prob 0.2400633333333333\n",
      "Steps = 24122, Episode 518 with reward = 199.0\n",
      "Exploring with prob 0.2337300000000001\n",
      "Steps = 24215, Episode 519 with reward = 92.0\n",
      "Steps = 24415, Episode 520 with reward = 199.0\n",
      "Exploring with prob 0.22423000000000004\n",
      "Steps = 24615, Episode 521 with reward = 199.0\n",
      "Steps = 24815, Episode 522 with reward = 199.0\n",
      "Steps = 25015, Episode 523 with reward = 199.0\n",
      "Steps = 25215, Episode 524 with reward = 199.0\n",
      "Steps = 25415, Episode 525 with reward = 199.0\n",
      "Steps = 25615, Episode 526 with reward = 199.0\n",
      "Steps = 25815, Episode 527 with reward = 199.0\n",
      "Steps = 26015, Episode 528 with reward = 199.0\n",
      "Exploring with prob 0.1735633333333334\n",
      "Steps = 26215, Episode 529 with reward = 199.0\n",
      "Steps = 26415, Episode 530 with reward = 199.0\n",
      "Steps = 26615, Episode 531 with reward = 199.0\n",
      "Steps = 26815, Episode 532 with reward = 199.0\n",
      "Steps = 27015, Episode 533 with reward = 199.0\n",
      "Steps = 27215, Episode 534 with reward = 199.0\n",
      "Steps = 27415, Episode 535 with reward = 199.0\n",
      "Steps = 27615, Episode 536 with reward = 199.0\n",
      "Steps = 27815, Episode 537 with reward = 199.0\n",
      "Steps = 28015, Episode 538 with reward = 199.0\n",
      "Exploring with prob 0.11023000000000005\n",
      "Steps = 28215, Episode 539 with reward = 199.0\n",
      "Exploring with prob 0.10389666666666664\n",
      "Steps = 28415, Episode 540 with reward = 199.0\n",
      "Steps = 28615, Episode 541 with reward = 199.0\n",
      "Exploring with prob 0.09123000000000003\n",
      "Steps = 28815, Episode 542 with reward = 199.0\n",
      "Steps = 29015, Episode 543 with reward = 199.0\n",
      "Steps = 29215, Episode 544 with reward = 199.0\n",
      "Steps = 29415, Episode 545 with reward = 199.0\n",
      "Steps = 29615, Episode 546 with reward = 199.0\n",
      "Steps = 29815, Episode 547 with reward = 199.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = 30000\n",
    "epsilon = LinearSchedule(steps, 0.05, 1.0)\n",
    "lr = 2e-4\n",
    "batch_size = 32\n",
    "gamma = 1\n",
    "\n",
    "dqn = DQN()\n",
    "dqn.apply(init_weights)\n",
    "agent = DQN_learn(dqn, lr, epsilon, gamma, batch_size, env.action_space)\n",
    "\n",
    "done = True\n",
    "\n",
    "episode_rew = 0\n",
    "episode_count = 0\n",
    "\n",
    "for t in range(steps):\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        act = agent.reset(obs)                    \n",
    "        print(\"Steps = \" + str(t) + \", Episode \" + str(episode_count) + \" with reward = \" + str(episode_rew))\n",
    "        \n",
    "        episode_rew = 0\n",
    "        episode_count = episode_count + 1\n",
    "        \n",
    "    obs, rew, done, _ = env.step(act)   \n",
    "    if done:        \n",
    "        rew = 0\n",
    "    act = agent.step(obs, rew, done)\n",
    "    episode_rew = episode_rew + rew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = 1000\n",
    "agent.epsilon = LinearSchedule(steps, 0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 with reward = 0\n",
      "Episode 1 with reward = 200.0\n",
      "Episode 2 with reward = 200.0\n",
      "Episode 3 with reward = 200.0\n",
      "Episode 4 with reward = 200.0\n",
      "Episode 5 with reward = 200.0\n",
      "Episode 6 with reward = 200.0\n",
      "Exploring with prob 0.01\n",
      "Episode 7 with reward = 200.0\n",
      "Episode 8 with reward = 200.0\n",
      "Episode 9 with reward = 200.0\n",
      "Episode 10 with reward = 200.0\n",
      "Episode 11 with reward = 200.0\n",
      "Episode 12 with reward = 200.0\n",
      "Episode 13 with reward = 200.0\n",
      "Episode 14 with reward = 200.0\n",
      "Episode 15 with reward = 200.0\n",
      "Episode 16 with reward = 200.0\n",
      "Episode 17 with reward = 200.0\n",
      "Episode 18 with reward = 200.0\n",
      "Episode 19 with reward = 200.0\n",
      "Episode 20 with reward = 200.0\n",
      "Episode 21 with reward = 200.0\n",
      "Episode 22 with reward = 200.0\n",
      "Episode 23 with reward = 200.0\n",
      "Episode 24 with reward = 200.0\n",
      "Episode 25 with reward = 200.0\n",
      "Episode 26 with reward = 200.0\n",
      "Episode 27 with reward = 200.0\n",
      "Episode 28 with reward = 200.0\n",
      "Episode 29 with reward = 200.0\n",
      "Episode 30 with reward = 200.0\n",
      "Episode 31 with reward = 200.0\n",
      "Episode 32 with reward = 200.0\n",
      "Episode 33 with reward = 200.0\n",
      "Episode 34 with reward = 200.0\n",
      "Episode 35 with reward = 200.0\n",
      "Episode 36 with reward = 200.0\n",
      "Episode 37 with reward = 200.0\n",
      "Episode 38 with reward = 200.0\n",
      "Episode 39 with reward = 200.0\n",
      "Episode 40 with reward = 200.0\n",
      "Episode 41 with reward = 200.0\n",
      "Episode 42 with reward = 200.0\n",
      "Episode 43 with reward = 200.0\n",
      "Episode 44 with reward = 200.0\n",
      "Episode 45 with reward = 200.0\n",
      "Episode 46 with reward = 200.0\n",
      "Episode 47 with reward = 200.0\n",
      "Episode 48 with reward = 200.0\n",
      "Episode 49 with reward = 200.0\n",
      "Episode 50 with reward = 200.0\n",
      "Episode 51 with reward = 200.0\n",
      "Episode 52 with reward = 200.0\n",
      "Episode 53 with reward = 200.0\n",
      "Episode 54 with reward = 200.0\n",
      "Episode 55 with reward = 200.0\n",
      "Episode 56 with reward = 200.0\n",
      "Episode 57 with reward = 200.0\n",
      "Episode 58 with reward = 200.0\n",
      "Episode 59 with reward = 200.0\n",
      "Episode 60 with reward = 200.0\n",
      "Episode 61 with reward = 200.0\n",
      "Episode 62 with reward = 200.0\n",
      "Exploring with prob 0.01\n",
      "Episode 63 with reward = 200.0\n",
      "Episode 64 with reward = 200.0\n",
      "Episode 65 with reward = 200.0\n",
      "Episode 66 with reward = 200.0\n",
      "Episode 67 with reward = 200.0\n",
      "Episode 68 with reward = 200.0\n",
      "Episode 69 with reward = 200.0\n",
      "Episode 70 with reward = 200.0\n",
      "Episode 71 with reward = 200.0\n",
      "Episode 72 with reward = 200.0\n",
      "Episode 73 with reward = 200.0\n",
      "Episode 74 with reward = 200.0\n",
      "Episode 75 with reward = 200.0\n",
      "Episode 76 with reward = 200.0\n",
      "Episode 77 with reward = 200.0\n",
      "Episode 78 with reward = 200.0\n",
      "Episode 79 with reward = 200.0\n",
      "Episode 80 with reward = 200.0\n",
      "Episode 81 with reward = 200.0\n",
      "Episode 82 with reward = 200.0\n",
      "Episode 83 with reward = 200.0\n",
      "Episode 84 with reward = 200.0\n",
      "Episode 85 with reward = 200.0\n",
      "Episode 86 with reward = 200.0\n",
      "Episode 87 with reward = 200.0\n",
      "Episode 88 with reward = 200.0\n",
      "Episode 89 with reward = 200.0\n",
      "Episode 90 with reward = 200.0\n",
      "Episode 91 with reward = 200.0\n",
      "Episode 92 with reward = 200.0\n",
      "Episode 93 with reward = 200.0\n",
      "Episode 94 with reward = 200.0\n",
      "Episode 95 with reward = 200.0\n",
      "Episode 96 with reward = 200.0\n",
      "Episode 97 with reward = 200.0\n",
      "Exploring with prob 0.01\n",
      "Episode 98 with reward = 200.0\n",
      "Episode 99 with reward = 200.0\n",
      "Episode 100 with reward = 200.0\n"
     ]
    }
   ],
   "source": [
    "#Testing Agent\n",
    "\n",
    "done = True\n",
    "\n",
    "episode_rew = 0\n",
    "episode_count = 0\n",
    "res = []\n",
    "\n",
    "while episode_count <= 100:\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        act = agent.reset(obs)            \n",
    "        \n",
    "        print(\"Episode \" + str(episode_count) + \" with reward = \" + str(episode_rew))\n",
    "        res.append(episode_rew)\n",
    "        episode_rew = 0\n",
    "        episode_count = episode_count + 1\n",
    "        \n",
    "    obs, rew, done, _ = env.step(act)       \n",
    "    act = agent.step(obs, rew, done)\n",
    "    episode_rew = episode_rew + rew\n",
    "\n",
    "#     env.render()\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res[1:]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result for 400th episode:__\n",
    "![last_episode](img/cartpole4.gif \"Cartpole\")\n",
    "__Result for 500th episode:__\n",
    "![last_episode](img/cartpole5.gif \"Cartpole\")\n",
    "__Result after 30,000 steps:__\n",
    "![last_episode](img/cartpole_final.gif \"Cartpole\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
